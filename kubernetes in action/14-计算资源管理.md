## 计算资源管理

#### 1.为pod申请资源（保证容器能获得需要资源的最小量）
* 定义Pod时，可以指定容器对资源的请求量(request)和限制量(limit)
  ```yaml
  #request-pod.yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: requests-pod
  spec:
    containers:
    - image: busybox
      command: ["dd", "if=/dev/zero", "of=/dev/null"] # dd命令会消耗尽可能多的CPU
      name: main
      resources:
        requests: #申请
          cpu: 200m #200micro core = 1/5 CPU即一个CPU时间的1/5
          memory: 10Mi #10MB的内存
  ```
  为容器声明需要1/5个CPU核的时间可以正常运行，五个同样的pod(或容器)可以足够快地运行在一个CPU核上，以及10MB的内存。可以在pod上运行top 命令
  ```shell
  $ kubectl exec -it request-pod top
  Mem: 1888976K used, 117440K free, 4028K shrd, 40380K buff, 448432K cached
  CPU: 15.5% usr 37.7% sys  0.0% nic 46.4% idle  0.0% io  0.0% irq  0.2% sirq
  Load average: 1.23 0.65 0.45 3/874 12
    PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
      1     0 root     R     1308  0.0   1 50.3 dd if /dev/zero of /dev/null
      8     0 root     R     1316  0.0   0  0.0 top
  ```
  **运行minikube的虚拟机共两个核**，这里占了50%即为一个核，超过了request，因为**requests不会限制**容器可以使用的CPU数量等资源，一个软性要求。

* request影响调度
  * request指定了资源最小值，调度器会将pod调度到未分配量满足的节点上。此外调度器的依据不是**资源的实际使用量**，而且节点的部署的pod的**申请资源量**的总和，为了保证已部署任务的资源。
  * 调度器。先对节点列表过滤，然后用优先级函数排序，有LeastRequestedPriority和MostRequestedPriority，前者优先将pod 调度到请求量少的节点上，后者优先调度到请求量多的节点，便于紧凑编排pod保持节点空闲，便于移除。
  * 查看节点资源总量
    ```shell
    kubectl describe node
    可以看到节点的资源总量：
    Capacity: #总量
      cpu:                2
      ephemeral-storage:  20508240Ki
      hugepages-1Gi:      0
      hugepages-2Mi:      0
      memory:             2006416Ki
      pods:               110
    Allocatable: #可分配量
      cpu:                2
      ephemeral-storage:  18900393953
      hugepages-1Gi:      0
      hugepages-2Mi:      0
      memory:             1904016Ki
      pods:               110
    ...
    Allocated resources: #已分配量
    ...
    ```
  * 在部署一个cpu为800m的pod
    ```
    kubectl run requests-pod-2 --image=busybox --restart Never --requests='cpu=800m,memory=20Mi' -- dd if=/dev/zero of=/dev/null
    ```
    两个pod的cpu总量为1cpu，然后创建**CPU=1(不是1000m)**的pod，会处于<pending>状态，```describe pod```发现资源不够，```describe node```发现其他命名空间的pod也占了CPU资源所以不够，未使用的CPU时间将按比例分配，其他进程处于空闲状态的CPU可以使用全部CPU
  * **自定义资源**: 可以自定义资源并且在pod中申请。可以通过HTTP的PATCH请求来加入节点API对象，资源数量必须为整数，将自动从capacity复制到allocatable。在创建pod时可以在spc的resource.request字段申请。

#### 限制容器可用资源:limit
* CPU可压缩，可以在不影响容器内进程的情况下限制使用量；内存不可压缩，分配之后在进程主动释放前无法回收。如果不限制，容器可能用掉所有可用内存，住新调度的pod是基于内存的申请量而不是实际使用量，所以可能影响别的pod的使用情况。
* 可以为pod指定资源，进程消耗不允许超过(未设置情况下requests等于limits)。且所有limits的总和可以超过100%，此时一些容器将被杀掉
* 超过limits时，CPU可压缩，只是进程分配无法超过limit而已；而对应内存，申请超过limit时会法师OOM，进程被杀死重启（kubelet每次失败会把重启时间翻倍直到为5分钟）
* 容器中的应用看待limits：部署limited-pod.yaml，容器限制CPU为1，内存为20Mi，查看资源情况
  ```
  Mem: 1913452K used, 92964K free, 4584K shrd, 41552K buff, 508956K cached
  CPU: 16.8% usr 38.8% sys  0.0% nic 44.2% idle  0.0% io  0.0% irq  0.0% sirq
  Load average: 0.83 0.95 1.16 3/916 13
    PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
      1     0 root     R     1308  0.0   1 50.0 dd if /dev/zero of /dev/null
      7     0 root     R     1316  0.0   1  0.0 top
  ```
  内存占用为1913452K，远大于20M，**top显示了运行容器的节点的内存**，可能出现的问题，JVM按照物理机内存分配**最大堆**大小，可能超出limits。再看CPU，容器内可以看到**全部核**，不会因为设定limit为1只暴露一个核，而且暴露**1/n的CPU运行时间**，可以通过Downward API将CPU限额传给容器，或者通过/sys/fs/cgroup/cpu/cpu.cfs.quota_.us，/sys/fs/cgroup/cpu/cpu.cfs.period_.us从**cgroup系统**获取CPU限制